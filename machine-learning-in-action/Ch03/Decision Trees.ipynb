{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate entropy of given dataset\n",
    "from math import log\n",
    "\n",
    "\n",
    "def calc_info_entropy(dataset):\n",
    "    freq = dict() # Frequdncies of each probal situation\n",
    "    for vect in dataset:\n",
    "        label = vect[-1]\n",
    "        if label not in freq:\n",
    "            freq[label] = 0\n",
    "        freq[label] += 1\n",
    "    total = len(dataset)\n",
    "    entropy = 0\n",
    "    for k in freq:\n",
    "        prob = freq[k] / total\n",
    "        entropy -= prob * log(prob, 2)\n",
    "    return entropy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample dataset\n",
    "def create_dataset():\n",
    "    dataset = [\n",
    "        [1, 1, 'yes'],\n",
    "        [1, 1, 'yes'],\n",
    "        [1, 0, 'no'],\n",
    "        [0, 1, 'no'],\n",
    "        [0, 1, 'no']\n",
    "    ]\n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    return dataset, labels\n",
    "\n",
    "dataset, labels = create_dataset()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_info_entropy(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'yes'], [1, 'yes'], [0, 'no']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split dataset per feature\n",
    "def split_dataset(dataset, feat_axis, feat_val):\n",
    "    result = list()\n",
    "    for sample in dataset:\n",
    "        if sample[feat_axis] == feat_val:\n",
    "            rest = sample[ : feat_axis]\n",
    "            rest.extend(sample[feat_axis + 1 : ])\n",
    "            result.append(rest)\n",
    "    return result\n",
    "\n",
    "split_dataset(dataset, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best split way\n",
    "def find_best_split(dataset):\n",
    "    n_features = len(dataset[0]) - 1\n",
    "    org_entropy = calc_info_entropy(dataset)\n",
    "    best_split_feat = -1\n",
    "    max_info_gain = 0\n",
    "    for feat_axis in range(n_features):\n",
    "        feat_vals = [x[feat_axis] for x in dataset]\n",
    "        uq_feat_vals = set(feat_vals)\n",
    "        for val in uq_feat_vals:\n",
    "            split_try = split_dataset(dataset, feat_axis, val)\n",
    "            new_entropy = calc_info_entropy(split_try)\n",
    "            info_gain = org_entropy - new_entropy\n",
    "            if info_gain > max_info_gain:\n",
    "                max_info_gain = info_gain\n",
    "                best_split_feat = feat_axis\n",
    "    return best_split_feat\n",
    "\n",
    "find_best_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If all of the features have been introduced to split,\n",
    "# but there are different labels still,\n",
    "# we will use voting to decide the classify\n",
    "import operator\n",
    "\n",
    "\n",
    "def final_vote(labels):\n",
    "    votes = dict()\n",
    "    for label in labels:\n",
    "        if label not in votes:\n",
    "            votes[label] = 0\n",
    "        votes[label] += 1\n",
    "    sorted_votes = sorted(\n",
    "        votes.items(),\n",
    "        key=operator.itemgetter(1),\n",
    "        reverse=True\n",
    "    )\n",
    "    return sorted_votes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('a', 1), ('b', 2)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'a': 1, 'b': 2}\n",
    "b = sorted(\n",
    "    a.items(),\n",
    "    key=operator.itemgetter(1)\n",
    ")\n",
    "a.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create decision tree\n",
    "def create_tree(dataset, labels):\n",
    "    # copy labels to prevent changes on original\n",
    "    feat_labels = labels[:]\n",
    "    # Recurse base\n",
    "    class_labels = [x[-1] for x in dataset]\n",
    "    if len(set(class_labels)) == 1:\n",
    "        return class_labels[0]\n",
    "    if len(labels) == 0:\n",
    "        return final_vote(class_labels)\n",
    "    # Recurse body\n",
    "    best_feat = find_best_split(dataset)\n",
    "    best_feat_label = feat_labels[best_feat]\n",
    "    del(feat_labels[best_feat])\n",
    "    sub_labels = feat_labels[:]\n",
    "    tree = {best_feat_label: dict()}\n",
    "    for val in set([x[best_feat] for x in dataset]):\n",
    "        tree[best_feat_label][val] = \\\n",
    "            create_tree(\n",
    "                split_dataset(dataset, best_feat, val),\n",
    "                sub_labels\n",
    "            )\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test create_tree() function\n",
    "create_tree(dataset, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try to figure part of tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "decision_node = dict(boxstyle=\"sawtooth\", fc=\"white\")\n",
    "leaf_node = dict(boxstyle=\"round4\", fc=\"white\")\n",
    "arrow_args = dict(arrowstyle=\"<-\")\n",
    "\n",
    "def plot_node(node_text, cent_pt, parent_pt, node_type):\n",
    "    create_plot.ax1.annotate(\n",
    "        node_text,\n",
    "        xy=parent_pt,\n",
    "        xycoords='axes fraction',\n",
    "        xytext=cent_pt,\n",
    "        textcoords=\"axes fraction\",\n",
    "        va=\"center\",\n",
    "        ha=\"center\",\n",
    "        bbox=node_type,\n",
    "        arrowprops=arrow_args\n",
    "    )\n",
    "    \n",
    "def create_plot():\n",
    "    fig = plt.figure(1, facecolor=\"white\")\n",
    "    fig.clf()\n",
    "    create_plot.ax1 = plt.subplot(111, frameon=False)\n",
    "    plot_node(\"Decision Node\", (0.5, 0.1), (0.1, 0.5), decision_node)\n",
    "    plot_node(\"Leaf Node\", (0.8, 0.1), (0.3, 0.8), leaf_node)\n",
    "    plt.show()\n",
    "        \n",
    "    \n",
    "create_plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get num of leaf nodes\n",
    "def get_leaf_num(tree):\n",
    "    leaf_num = 0\n",
    "    # recurse base\n",
    "    if type(tree) is not dict:\n",
    "        leaf_num = 1\n",
    "    # recurse body\n",
    "    else:\n",
    "        root = list(tree.keys())[0]\n",
    "        for k in tree[root]:\n",
    "            leaf_num += get_leaf_num(tree[root][k])\n",
    "    return leaf_num\n",
    "\n",
    "get_leaf_num(create_tree(dataset, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get depth of tree\n",
    "def get_tree_depth(tree):\n",
    "    tree_depth = 0\n",
    "    # Recurse base\n",
    "    if type(tree) is not dict:\n",
    "        tree_depth = 0\n",
    "    # Recurse body\n",
    "    else:\n",
    "        root = list(tree.keys())[0]\n",
    "        max_depth = 0\n",
    "        for k in tree[root]:\n",
    "            depth = get_tree_depth(tree[root][k])\n",
    "            if depth > max_depth:\n",
    "                max_depth = depth\n",
    "        tree_depth = max_depth + 1\n",
    "    return tree_depth\n",
    "\n",
    "\n",
    "get_tree_depth(create_tree(dataset, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use decision tree to classify\n",
    "def tree_classify(tree, x_in, x_labels):\n",
    "    # Recurse base\n",
    "    if type(tree) is not dict:\n",
    "        return tree\n",
    "    # Recurse body\n",
    "    root = list(tree.keys())[0]\n",
    "    feat_index = x_labels.index(root)\n",
    "    for feat_val in tree[root]:\n",
    "        if x_in[feat_index] == feat_val:\n",
    "            return tree_classify(tree[root][feat_val], x_in, x_labels)\n",
    "\n",
    "        \n",
    "tree_classify(\n",
    "    create_tree(dataset, labels),\n",
    "    [1, 1],\n",
    "    ['no surfacing', 'flippers']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store decision tree\n",
    "import pickle\n",
    "\n",
    "\n",
    "def store_tree(tree, store_file):\n",
    "    with open(store_file, 'wb') as f:\n",
    "        pickle.dump(tree, f)\n",
    "        \n",
    "        \n",
    "store_tree(\n",
    "    create_tree(dataset, labels),\n",
    "    'fish_decision_tree.pkl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "# Load decisiin tree from pickle fie\n",
    "def load_tree(store_file):\n",
    "    with open(store_file, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "tree = load_tree('fish_decision_tree.pkl')\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['young', 'myope', 'no', 'reduced', 'no lenses'],\n",
       "  ['young', 'myope', 'no', 'normal', 'soft'],\n",
       "  ['young', 'myope', 'yes', 'reduced', 'no lenses'],\n",
       "  ['young', 'myope', 'yes', 'normal', 'hard'],\n",
       "  ['young', 'hyper', 'no', 'reduced', 'no lenses'],\n",
       "  ['young', 'hyper', 'no', 'normal', 'soft'],\n",
       "  ['young', 'hyper', 'yes', 'reduced', 'no lenses'],\n",
       "  ['young', 'hyper', 'yes', 'normal', 'hard'],\n",
       "  ['pre', 'myope', 'no', 'reduced', 'no lenses'],\n",
       "  ['pre', 'myope', 'no', 'normal', 'soft'],\n",
       "  ['pre', 'myope', 'yes', 'reduced', 'no lenses'],\n",
       "  ['pre', 'myope', 'yes', 'normal', 'hard'],\n",
       "  ['pre', 'hyper', 'no', 'reduced', 'no lenses'],\n",
       "  ['pre', 'hyper', 'no', 'normal', 'soft'],\n",
       "  ['pre', 'hyper', 'yes', 'reduced', 'no lenses'],\n",
       "  ['pre', 'hyper', 'yes', 'normal', 'no lenses'],\n",
       "  ['presbyopic', 'myope', 'no', 'reduced', 'no lenses'],\n",
       "  ['presbyopic', 'myope', 'no', 'normal', 'no lenses'],\n",
       "  ['presbyopic', 'myope', 'yes', 'reduced', 'no lenses'],\n",
       "  ['presbyopic', 'myope', 'yes', 'normal', 'hard'],\n",
       "  ['presbyopic', 'hyper', 'no', 'reduced', 'no lenses'],\n",
       "  ['presbyopic', 'hyper', 'no', 'normal', 'soft'],\n",
       "  ['presbyopic', 'hyper', 'yes', 'reduced', 'no lenses'],\n",
       "  ['presbyopic', 'hyper', 'yes', 'normal', 'no lenses']],\n",
       " ['age', 'prescript', 'astigmatic', 'tearrate'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format lenses dataset\n",
    "def get_lenses_dataset():\n",
    "    dataset = list()\n",
    "    labels = ['age', 'prescript', 'astigmatic', 'tearrate']\n",
    "    with open('lenses.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            dataset.append([x.strip() for x in line.split('\\t')])\n",
    "    return dataset, labels\n",
    "\n",
    "get_lenses_dataset()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tearrate': {'normal': {'astigmatic': {'no': {'age': {'presbyopic': {'prescript': {'hyper': 'soft',\n",
       "        'myope': 'no lenses'}},\n",
       "      'pre': 'soft',\n",
       "      'young': 'soft'}},\n",
       "    'yes': {'age': {'presbyopic': {'prescript': {'hyper': 'no lenses',\n",
       "        'myope': 'hard'}},\n",
       "      'pre': {'prescript': {'hyper': 'no lenses', 'myope': 'hard'}},\n",
       "      'young': 'hard'}}}},\n",
       "  'reduced': 'no lenses'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, labels = get_lenses_dataset()\n",
    "create_tree(dataset, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
